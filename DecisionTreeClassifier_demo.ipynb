{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DecisionTreeClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAkwiebhxYQW",
        "colab_type": "text"
      },
      "source": [
        "Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB3BQIJE9FGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import urllib\n",
        "import pandas as pd\n",
        "import json\n",
        "from timeit import default_timer as timer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYr-kzlGel9E",
        "colab_type": "text"
      },
      "source": [
        "Make a decision tree model based on CART algorithm to pick the best feature and its threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh_yP_LZ9hT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecisionTreeClassifier:\n",
        "    # Tree initialization\n",
        "    def __init__(self, dataset, max_depth, min_size):\n",
        "        self.tree = self.build_decision_tree(dataset, max_depth, min_size)\n",
        "    \n",
        "    # Splitting the data according to the threshold\n",
        "    def check_split(self, dataset, feature, threshold):\n",
        "        \"\"\"\n",
        "        If the value of the given feature is less than the threshold,\n",
        "        it will be the left node. If it is greater than or equal to the \n",
        "        threshold, it will be the right node.\n",
        "\n",
        "        >>> check_split(dataset, feature, threshold)\n",
        "        Pandas.DataFrame\n",
        "        \"\"\"\n",
        "        left_node, right_node = None, None\n",
        "        left = dataset.loc[dataset[feature] < threshold]\n",
        "        if len(left):\n",
        "            left_node = left\n",
        "        else:\n",
        "            return None\n",
        "        right = dataset.loc[dataset[feature] >= threshold]\n",
        "        if len(right):\n",
        "            right_node = right\n",
        "        else:\n",
        "            return None\n",
        "        return left_node, right_node\n",
        "\n",
        "    # Find the gini index\n",
        "    def find_gini_index(self, sliced_df, temp_labels):\n",
        "        \"\"\"\n",
        "        It will return the gini index if the dataset is split by the given\n",
        "        label (temp_labels).\n",
        "\n",
        "        >>> find_gini_index(sliced_df, temp_labels)\n",
        "        0.1827\n",
        "        \"\"\"\n",
        "        num_of_data = float(sum([len(slice) for slice in sliced_df]))\n",
        "        gini_index = 0.0\n",
        "        for slice in sliced_df:\n",
        "            size = float(len(slice))\n",
        "            if size == 0:\n",
        "              continue\n",
        "            temp_score = 0.0\n",
        "            for label in temp_labels:\n",
        "                # TODO change price_range to the last name of the column\n",
        "                p = (slice.price_range == label).sum() / size\n",
        "                temp_score += p**2\n",
        "            gini_index += (1.0 - temp_score) * (size / num_of_data)\n",
        "        return gini_index\n",
        "\n",
        "    # Creating the end of branch for the tree\n",
        "    def end_of_branch(self, dataset):\n",
        "        \"\"\"\n",
        "        When the remaining dataset can not be further splitted or the depth \n",
        "        of the tree is reaching maximum, the end of branch will be created \n",
        "        consisting of a possible label.\n",
        "\n",
        "        >>> end_of_branch(dataset)\n",
        "        label\n",
        "        \"\"\"\n",
        "        count = 0\n",
        "        possible_label = None\n",
        "        # TODO change price_range to the last name of the column\n",
        "        for label in dataset.price_range.unique().tolist():\n",
        "            currentCount = len([x for x in dataset.price_range == label if x == True])\n",
        "            if currentCount > count:\n",
        "                count = currentCount\n",
        "                possible_label = label\n",
        "        return possible_label\n",
        "\n",
        "    # Finding the best split based on the Gini Index\n",
        "    def best_split(self, dataset):\n",
        "        \"\"\"\n",
        "        This function will iterate through all the labels, and all the values \n",
        "        of that label to find an optimum split with the smallest Gini Index.\n",
        "\n",
        "        When end of branch condition is satisfied\n",
        "        >>> best_split(dataset)\n",
        "        label\n",
        "\n",
        "        When a new split is found\n",
        "        >>> best_split(dataset)\n",
        "        {'feature': feature, 'value': threshold, 'sliced_df': sliced_df}\n",
        "        \"\"\"\n",
        "        # TODO change price_range to the last name of the column\n",
        "        temp_labels = list(set(dataset.price_range.values.tolist()))\n",
        "        feature, threshold, gini_index, sliced_df = None, 0.0, 1, None\n",
        "        # TODO change wifi to the end of feature column\n",
        "        for col in dataset.loc[:,:'wifi'].columns.values.tolist():\n",
        "            for val in dataset[col].unique():\n",
        "                temp_sliced_df = self.check_split(dataset, col, val)\n",
        "                if temp_sliced_df == None:\n",
        "                    continue\n",
        "                temp_gini_index = self.find_gini_index(temp_sliced_df, temp_labels)\n",
        "                if temp_gini_index < gini_index:\n",
        "                    feature = col\n",
        "                    threshold = val\n",
        "                    gini_index = temp_gini_index\n",
        "                    sliced_df = temp_sliced_df\n",
        "                else:\n",
        "                  continue\n",
        "        if feature == None:\n",
        "            this_label = self.end_of_branch(dataset)\n",
        "            return this_label\n",
        "        return {'feature': feature, 'value': threshold, 'sliced_df': sliced_df}\n",
        "\n",
        "    # Method to recursively split node\n",
        "    def split_node(self, node, max_depth, min_size, current_depth):\n",
        "        \"\"\"\n",
        "        Checking whether the conditions of end of branch is satisfied or \n",
        "        the node can be further splitted.\n",
        "\n",
        "        >>> split_node(node, max_depth, min_size, current_depth)\n",
        "        None\n",
        "        \"\"\"\n",
        "        if isinstance(node, int):\n",
        "            return\n",
        "        left, right = node['sliced_df']\n",
        "        del(node['sliced_df'])\n",
        "        if left.empty or right.empty:\n",
        "            node['left'] = node['right'] = self.end_of_branch(left + right)\n",
        "            return\n",
        "        if current_depth >= max_depth:\n",
        "            node['left'], node['right'] = self.end_of_branch(left), self.end_of_branch(right)\n",
        "            return\n",
        "        if len(left) <= min_size:\n",
        "            node['left'] = self.end_of_branch(left)\n",
        "        else:\n",
        "            node['left'] = self.best_split(left)\n",
        "            self.split_node(node['left'], max_depth, min_size, current_depth+1)\n",
        "        if len(right) <= min_size:\n",
        "            node['right'] = self.end_of_branch(right)\n",
        "        else:\n",
        "            node['right'] = self.best_split(right)\n",
        "            self.split_node(node['right'], max_depth, min_size, current_depth+1)\n",
        "\n",
        "    # Building the decision tree based on the requirements\n",
        "    def build_decision_tree(self, dataset, max_depth, min_size):\n",
        "        \"\"\"\n",
        "        >>> build_decision_tree(dataset, max_depth, min_size)\n",
        "        {'feature': feature, 'value': threshold, 'sliced_df': sliced_df}\n",
        "        \"\"\"\n",
        "        root = self.best_split(dataset)\n",
        "        self.split_node(root, max_depth, min_size, 1)\n",
        "        self.create_json(root)\n",
        "        return root\n",
        "\n",
        "    # Traversing the tree based on the feature and threshold of each node\n",
        "    def recursive_predict(self, node, data_row):\n",
        "        \"\"\"\n",
        "        >>> recursive_predict(node, data_row)\n",
        "        label\n",
        "        \"\"\"\n",
        "        if data_row[node['feature']].unique()[0] < node['value']:\n",
        "            if isinstance(node['left'], dict):\n",
        "                return self.recursive_predict(node['left'], data_row)\n",
        "            else:\n",
        "                return node['left']\n",
        "        else:\n",
        "            if isinstance(node['right'], dict):\n",
        "                return self.recursive_predict(node['right'], data_row)\n",
        "            else:\n",
        "                return node['right']\n",
        "\n",
        "    # Initiating the prediction\n",
        "    def predict(self, data_row):\n",
        "        node = self.tree\n",
        "        return self.recursive_predict(node, data_row)\n",
        "    \n",
        "    # Testing the accuracy of trained model\n",
        "    def accuracy_test(self, data, result):\n",
        "        \"\"\"\n",
        "        For each row in the testing set, each one will be predicted.\n",
        "        True/false prediction will be counted towards the result.\n",
        "\n",
        "        >>> accuracy_test(data, result)\n",
        "        0.76\n",
        "        \"\"\"\n",
        "        indexes = len(data.index.values.tolist())\n",
        "        true_pred = 0\n",
        "        false_pred = 0\n",
        "        for i in range(indexes):\n",
        "            prediction = self.predict(data.iloc[[i]])\n",
        "            # TODO change price_range to the last name of the column\n",
        "            actual = result.iloc[[i]]['price_range'].values[0]\n",
        "            if prediction == actual:\n",
        "                true_pred += 1\n",
        "                continue\n",
        "            false_pred += 1\n",
        "        return true_pred / (true_pred+false_pred)\n",
        "    \n",
        "    # Recursively make a dictionary to save the feature and threshold of nodes\n",
        "    def recursive_tree_traverse(self, node):\n",
        "        if isinstance(node, dict):\n",
        "            return {'feature': node['feature'],\n",
        "                    'threshold': int(node['value']),\n",
        "                    'left': self.recursive_tree_traverse(node['left']),\n",
        "                    'right': self.recursive_tree_traverse(node['right'])}\n",
        "        else:\n",
        "            return int(node)\n",
        "\n",
        "    # Create a json based on the tree dictionary\n",
        "    def create_json(self, root):\n",
        "        self.tree_dict = self.recursive_tree_traverse(root)\n",
        "        with open(\"decision_tree_model.json\", \"w\") as write_file:\n",
        "            json.dump(self.tree_dict, write_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI3QPp8z9Nbm",
        "colab_type": "text"
      },
      "source": [
        "Importing and Splitting Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3nEenqYvaZt",
        "colab_type": "code",
        "outputId": "8cb34335-79e1-49d1-e2fa-832857b3c2be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Import dataset\n",
        "dataURL = 'https://raw.githubusercontent.com/farhanoktvn/dataset/master/mobile.csv'\n",
        "response = urllib.request.urlopen(dataURL)\n",
        "\n",
        "# Read data from CSV file and save into Pandas dataframe\n",
        "df = pd.read_csv(response)\n",
        "\n",
        "# Splitting dataset into training and testing\n",
        "train_set = df.sample(frac = 0.8)\n",
        "test_set = df.drop(train_set.index)\n",
        "\n",
        "time_start = timer()\n",
        "model = DecisionTreeClassifier(train_set, 14, 1)\n",
        "time_end = timer()\n",
        "print(\"Time elapsed: {}\".format(time_end - time_start))\n",
        "print(\"Root node - Feature: {}, threshold: {}.\".format(model.tree['feature'], model.tree['value']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time elapsed: 280.570282376\n",
            "Root node - Feature: ram, threshold: 2258.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHCgyQdN1fyK",
        "colab_type": "text"
      },
      "source": [
        "Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj_6mJeV1fI2",
        "colab_type": "code",
        "outputId": "84f9508e-ffdf-40b6-de46-4d586e494867",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_data = test_set.loc[:,:'wifi']\n",
        "test_result = test_set.loc[:,'price_range':]\n",
        "accuracy = model.accuracy_test(test_data, test_result)\n",
        "print(accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.86\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}